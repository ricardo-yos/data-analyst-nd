{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Data Analyst Nanodegree\n",
    "+ Project 3 - Data Wrangle OpenStreetMaps Data\n",
    "+ Ricardo Yoshitomi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling the OpenStreetMap\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Area\n",
    "\n",
    "***\n",
    "\n",
    "The objective of this project is to use data munging techniques to clean and audit the OpenStreetMap data for a chosen part of the world. The OpenStreetMap area that I've chosen is the city of Santo André, SP located in Brazil. Since Santo André is not in the 200 most popular cities in the world, I downloaded the OSM dataset in XML format of a pre-selected area within the region of São Paulo that I obtained by searching in the custom extract field.\n",
    "\n",
    "+ https://www.openstreetmap.org/relation/298086\n",
    "+ https://mapzen.com/data/metro-extracts/metro/sao-paulo_brazil/\n",
    "\n",
    "I've chosen this map because it is my hometown and I am very curious to see some facts that I could not discover only by walking around the city. Santo André is a city located in the Metropolitan Region of São Paulo and it is part of a group of municipalities known as Greater ABC Region (<em>Região do Grande ABC</em>). All the codes and information I used in this project I found in [OSM XML - wiki](http://wiki.openstreetmap.org/wiki/OSM_XML), [Regular Expression HOWTO](https://docs.python.org/3/howto/regex.html), [w3schools](https://www.w3schools.com/sql/default.asp) and [stackoverflow](https://stackoverflow.com/) pages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenStreetMap Data Format\n",
    "\n",
    "***\n",
    "\n",
    "The OpenStreetMap data is storage in XML format. Basically it is a list of instances of three different core elements (also known as <em>data primitives</em>):\n",
    "\n",
    "+ <strong>Node</strong> is a point with a geographic position. It is defined by its coordinates (pairs of a latitude and a longitude) and node id. Nodes are often used to define the shape or \"path\" of a way, but can be used to define standalone point features. When used to define point features, a node will normally have at least one tag to define its purpose. For example, a restaurant may be tagged with `amenity=restaurant`.\n",
    "+ <strong>Way</strong> is an ordered list of nodes. It can be represented by a polyline if the way is open or a polygon if they form a closed loop. An open way describes a linear feature such as streets, roads, streams and railway lines. A closed way is a way where the last node is shared with the first node forming a closed loop. A closed way can be interpreted as an area, examples of areas include: \n",
    "    + `leisure=park` to define the perimeter of a park\n",
    "    + `amenity=school` to define the outline of a school\n",
    "+ <strong>Relation</strong> is ordered list of one or more nodes, ways and/or relations as members which is used to define logical or geographic relationships between other elements. A member of a relation can optionally have a role which describes the part that a particular feature plays within a relation.\n",
    "\n",
    "All types of data primitives (nodes, ways and relations) can have a tag to describe a specific feature:\n",
    "\n",
    "+ <strong>Tag</strong> consists of two free format text fields, a key and a value separated by an equals sign, `key = value`. For example, `highway=residential` defines the way as a road whose main function is to give access to people's homes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems Encontered in the Data\n",
    "***\n",
    "After converting the XML file into CSV format using the data.py script and importing it into a SQL database in order to perform some queries, I identified some problems in the data that will be discussed in the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overabbreviated Street Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I performed some basic querying in SQL to identify which type of street name abbreviations I could encounter. After that, I used regular expressions to identify specific cases more precisely. With the problems revealed, I iterated over each street word to correct them. The problems that I encountered are presented below:\n",
    "\n",
    "+ \"Av. Andrômeda\" : Abbreviated street type. Correct: \"Avenida Andrômeda\"\n",
    "+ \"Avenida Sen. Vergueiro\" : Abbreviated street name. Correct: \"Avenida Senador Vergueiro\"\n",
    "+ \"1ª Travessa da Estrada do Morro Grande\" : Contractions in ordinal indicators. Correct: \"Primeira Travessa da Estrada do Morro Grande\"\n",
    "\n",
    "The following code updates all the inconsistent substrings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "(...)\n",
    "\n",
    "street_type_re = re.compile(r'\\b\\w+\\S+\\.?', re.IGNORECASE)\n",
    "abbrev_street_re = re.compile(r'(\\b\\w+|_)[.]', re.IGNORECASE)\n",
    "num_street_re = re.compile(r'\\d[°ª]', re.IGNORECASE)\n",
    "lowercase_re = re.compile(r'\\b[a-z]+', re.LOCALE)\n",
    "postalcode_re = re.compile(r'\\d{5}[-]\\d{3}')\n",
    "\n",
    "\n",
    "expected = [\"Rua\", \"Avenida\", u\"Praça\", \"Travessa\", \"Alameda\", \"Largo\", \"Rodovia\", \"Complexo\", \"Estrada\", \"Rodoanel\", \"Passagem\"]\n",
    "\n",
    "mapping = { \"Av.\": \"Avenida\",\n",
    "            \"Sen.\": \"Senador\",\n",
    "            \"Prof.\": \"Professor\",\n",
    "            \"Dr.\": \"Doutor\",\n",
    "            \"Pres.\": \"Presidente\",\n",
    "            \"B.\": \"Barreto\",\n",
    "            u\"1ª\": \"Primeira\"\n",
    "          }\n",
    "\n",
    "allowed_lowercase = [\"da\", \"de\", \"do\", \"das\", \"dos\", \"e\"]\n",
    "         \n",
    "(...)\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    words_name = name.split(\" \")\n",
    "    if words_name not in expected:\n",
    "        for word in words_name:\n",
    "            if word in mapping:\n",
    "                name = name.replace(word, mapping[word])\n",
    "                \n",
    "(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Street Names without Street Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some addresses strings missing the street type (Rua, Avenida, Travessa, etc.). For this case, I searched for each incomplete address on Google Map to see which type of street I should add in the string. \n",
    "\n",
    "+ Correct \"Fernando Espírito Santo Alves de Mattos\" to \"Avenida Fernando Espírito Santo Alves de Mattos\"\n",
    "+ Correct \"Garcia Lorca\" to \"Rua Garcia Lorca\"\n",
    "\n",
    "The following code adds a new \"street type\" to the beginning of the address string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "(...)\n",
    "\n",
    "if words_name[0] not in expected:\n",
    "    if words_name[0] not in mapping:\n",
    "        if words_name[0] == \"Fernando\":\n",
    "            name = \"Avenida \" + name\n",
    "        elif words_name[0] == \"rua\":\n",
    "            pass\n",
    "        else:\n",
    "            name = \"Rua \" + name           \n",
    "\n",
    "(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Street Name Initialized with Lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the words in street names are not capitalized:\n",
    "\n",
    "+ \"avenida Sapopemba\" : Street type is not capitalized. Correct: \"Avenida Sapopemba\"\n",
    "+ \"Rua alexandre Galera\" : Street name is not capitalized. Correct: \"Rua Alexandre Galera\"\n",
    "\n",
    "The code below iterates over each name identifying the lowercase word and replaces it with the same capitalized word. The words \"da\", \"de\", \"do\", \"das\", \"dos\" and \"e\" are allowed within names in portuguese language. These words are the exceptions to the correction rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "(...)\n",
    "\n",
    "if word == word.lower():\n",
    "    if word not in allowed_lowercase:\n",
    "        name = name.replace(word, word.capitalize())            \n",
    "\n",
    "(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inconsistent Postal Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Postal Code format in Brazil (known as CEP - <em>Código de Endereçamento Postal</em>) is composed by 8 digits. These digits are split into 2 parts separated by a hyphen. The first part is composed by 5 digits and the second by 3. The structure of the \"CEP\" has the format XXXXX-XXX. After performing some basic queries in SQL I identified the following sort of problems in the dataset:\n",
    "\n",
    "+ 097912-60 :  Hyphen positioned in the wrong place. Correct: 09791-260\n",
    "+ 09060000 : Digits without hyphen. Correct: 09060-000\n",
    "+ 09832 400 : Space instead of hyphen. Correct: 09832-400\n",
    "+ 09790 - 400 : Spaces separating the hyphen from the digits. Correct: 09790-400\n",
    "\n",
    "The following code updated the inconsistent postal codes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "(...)\n",
    "\n",
    "def update_postalcode(code):\n",
    "    digits = []\n",
    "    for num in code:\n",
    "        if num not in [\"-\", \" \"]:\n",
    "            digits.append(num)\n",
    "    \n",
    "    code = \"\".join(digits[0:5])+\"-\"+\"\".join(digits[5:])\n",
    "    \n",
    "    return code\n",
    "\n",
    "(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending the Borders\n",
    "***\n",
    "Since the area of Santo André is not delimited by its borders, but actually, it is represented by a square in the Mapzen website, areas of surrounding cities are included within the dataset. In addition, I had to extend the border (square) when I was extracting the OSM XML file from the website because the area of Santo André is not large enough to attend the criteria of at least 50 MB size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> SELECT tags.value, COUNT(*) as count \n",
    "FROM (SELECT * FROM nodes_tags UNION ALL \n",
    "      SELECT * FROM ways_tags) tags\n",
    "WHERE tags.key LIKE '%city'\n",
    "GROUP BY tags.value\n",
    "ORDER BY count DESC\n",
    "LIMIT 6;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```html\n",
    "São Bernardo do Campo   2218\n",
    "Santo André             296\n",
    "São Caetano do Sul      165\n",
    "São Paulo               163\n",
    "Diadema                 145\n",
    "Mauá                    87\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results of the query, we can see that most part of the data belongs to São Bernardo do Campo which is a neighboring city of Santo André. It means that the extracted part of São Bernardo is much larger than the entire city of Santo André. All the cities in the results except São Paulo compose the Greater Region of ABC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postal Codes out of range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Correios](http://www.buscacep.correios.com.br/sistemas/buscacep/buscaFaixaCep.cfm) (Brazilian Mail Service) provides the CEP range of all cities in Brazil. We are most interested in the first 5 digits because it identifies the region of the city. We can see from the results bellow that the region of Greater ABC is identified by the digits 09XXX-XXX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```html\n",
    "São Paulo                 01000-001 to 05999-999\n",
    "São Paulo                 08000-000 to 08499-999\n",
    "Santo André               09000-001 to 09299-999\n",
    "Mauá                      09300-001 to 09399-999\n",
    "Ribeirão Pires            09400-001 to 09449-999\n",
    "São Caetano do Sul        09500-001 to 09599-999\n",
    "São Bernardo do Campo     09600-001 to 09899-999\n",
    "Diadema                   09900-001 to 09999-999\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "SELECT tags.value \n",
    "FROM (SELECT * FROM nodes_tags WHERE key='postcode' \n",
    "      UNION ALL \n",
    "      SELECT * FROM ways_tags WHERE key='postcode') tags\n",
    "WHERE NOT tags.value LIKE '09%' \n",
    "AND tags.value NOT BETWEEN '01000%' AND '05999%' \n",
    "AND tags.value NOT BETWEEN '08000%' AND '08499%';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```html\n",
    "11060-301\n",
    "13087-901\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two CEPs in the dataset that are out of range of valid CEPs for the analyzed region. The CEP: 11060-301 corresponds to the region of Santos/SP and CEP: 13087-901 to the region of Campinas/SP. I searched the incorrect CEPs in the dataset and by the street names I changed them to the correct one. \n",
    "+ 11060-301 : Avenida Padre Anchieta, 21 - São Bernardo do Campo/SP. Correct: 09891-420\n",
    "+ 13087-901 : Avenida Dom Pedro II, 2112 - Santo André/SP. Correct: 09080-001\n",
    "\n",
    "The following code updated the incorrect postal code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "(...)\n",
    "\n",
    "def update_postalcode(code):\n",
    "    correct_cep = {\"11060-301\":\"09891-420\", \"13087-901\": \"09080-001\"}\n",
    "    if code in correct_cep:\n",
    "        code = correct_cep[code]\n",
    "    \n",
    "    return code\n",
    "\n",
    "(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data Overview\n",
    "***\n",
    "This section is an overview about the dataset, the SQL queries were used to gather the basic statistics and some information about the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```html\n",
    "santo-andre_brazil.osm ........ 55.5 MB\n",
    "santo-andre.db ................ 31.8 MB\n",
    "nodes.csv ..................... 20.3 MB\n",
    "nodes_tags.csv ................ 0.66 MB\n",
    "ways.csv ...................... 2.5 MB\n",
    "ways_tags.csv ................. 4.7 MB\n",
    "ways_nodes.cv ................. 7.8 MB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> SELECT COUNT(*) FROM nodes;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "238699"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of ways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> SELECT COUNT(*) FROM ways;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40858"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of unique users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> SELECT COUNT(DISTINCT(e.uid))          \n",
    "FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) e;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "397"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 contributing users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> SELECT e.user, COUNT(*) as num\n",
    "FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e\n",
    "GROUP BY e.user\n",
    "ORDER BY num DESC\n",
    "LIMIT 10;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "AjBelnuovo          59812\n",
    "Bonix-Mapper        52649\n",
    "felipeacsi          17484\n",
    "poschon             14621\n",
    "MCPicoli            14377\n",
    "cxs                 10321\n",
    "StefanSP            9452\n",
    "patodiez            8809\n",
    "naoliv              7275\n",
    "Rub21               5962\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of contributions per year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> SELECT DATE(e.timestamp,'start of year') as YEAR, COUNT(*)\n",
    "FROM (SELECT timestamp FROM nodes UNION ALL SELECT timestamp FROM ways) e\n",
    "GROUP BY YEAR\n",
    "ORDER BY YEAR;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "2007-01-01   4228\n",
    "2008-01-01   1551\n",
    "2009-01-01   234\n",
    "2010-01-01   2689\n",
    "2011-01-01   28321\n",
    "2012-01-01   33803\n",
    "2013-01-01   31150\n",
    "2014-01-01   47705\n",
    "2015-01-01   23446\n",
    "2016-01-01   45201\n",
    "2017-01-01   61229\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Ideas\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 appearing amenities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> SELECT e.value, COUNT(*) as num\n",
    "FROM (SELECT key, value FROM nodes_tags UNION ALL SELECT key, value FROM ways_tags) e\n",
    "WHERE e.key='amenity'\n",
    "GROUP BY e.value\n",
    "ORDER BY num DESC\n",
    "LIMIT 10;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "parking               350\n",
    "school                250\n",
    "fuel                  236\n",
    "restaurant            187\n",
    "place_of_worship      181\n",
    "bank                  145\n",
    "pharmacy              94\n",
    "fast_food             83\n",
    "bench                 75\n",
    "telephone             71\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most popular fast food"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> SELECT e.value, COUNT(*) as num\n",
    "FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) e\n",
    "    JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='fast_food' UNION ALL SELECT DISTINCT(id) FROM ways_tags WHERE value='fast_food') i\n",
    "    ON e.id=i.id\n",
    "WHERE e.key='name'\n",
    "GROUP BY e.value\n",
    "ORDER BY num DESC\n",
    "LIMIT 3;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```html\n",
    "McDonald's     13\n",
    "Subway         11\n",
    "Burger King    3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Subway](img/subway.jpg)\n",
    "\n",
    "Although the result of the query indicates that McDonald's is the most popular fast food, actually Subway has the greatest number of franchises. According to [Diário do Grande ABC](http://www.dgabc.com.br/noticia/1939499/subway-ultrapassa-mcdonald-s-na-regiao) (regional newspaper of Greater ABC), Subway overcame McDonald's in the region. The difference in the results occurred probably because the dataset is not counting the number of franchises inside buildings such as Shopping Centers, and the OSM XML file only covers the region of Santo André and some part of neighboring cities (not the whole city).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of residential highways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> SELECT ways_tags.value, COUNT(*)\n",
    "FROM ways_tags\n",
    "    JOIN (SELECT DISTINCT(id) FROM ways_tags WHERE value='residential') i\n",
    "    ON ways_tags.id=i.id\n",
    "WHERE ways_tags.key='highway';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "residential   16924\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of highways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> SELECT key, COUNT(*)\n",
    "FROM ways_tags\n",
    "WHERE key='highway';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "highway   27501\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of residential highways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the results of the queries that 61.4% (16924/27501) of the highways are classified as residential, more than a half of the highways serve as an access to housing. It means that the region lacks expressways. The borders of each city confuse to one another and we don't know when a city begins and finishes. There are few highways that link the cities and the connection between the Greater ABC region and São Paulo is narrow. A consequence of this structure is that the traffic in the region is getting worse as the population of the region increases. Depending on the time of the day (rush hour), the traffic can reach some parts of residential highways. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are cycleway highways an alternative?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> SELECT ways_tags.value, COUNT(*)\n",
    "FROM ways_tags\n",
    "    JOIN (SELECT DISTINCT(id) FROM ways_tags WHERE value='cycleway') i\n",
    "    ON ways_tags.id=i.id\n",
    "WHERE ways_tags.key='highway';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "cycleway   20\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are lots of plans aimed to reduce the traffic in the region, one of these plans is the construction of cycleways. Encouraging people to let their cars at home to go to their work with a bicycle is a good practice. In addition to the contribution to the reduction of traffic congestion, it is also cheap, environmentally friendly and healthy. The map bellow indicates the cycleways in the Greater ABC region, we can see from the result of the query that 20 is the number of cycleways in the region. It is still a low number compared to the total number of highways, in terms of percentage, it is only 0.000727% (20/27501). \n",
    "\n",
    "There are plans to increase the number of cycleways in the city of São Paulo until the year of 2030. According to [Diário do Grande ABC](http://www.dgabc.com.br/Noticia/1936437/plano-preve-1-7-mil-km-de-ciclovias-em-sao-paulo-ate-2030), the city plans to have 1,7 thousand of kilometers of cycleways until the year of 2030. The extension of cycleways, today the city has 498,3 km ([CEPSP - Companhia de Engenharia de Tráfego](http://www.cetsp.com.br/consultas/bicicleta/mapa-de-infraestrutura-cicloviaria.aspx)), aims to connect the remote highways to the downtown. Maybe with this fact, the Greater ABC region will also have a larger number of cycleways in the future.\n",
    "\n",
    "![Cycleway](img/cycleway.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggestions for Improvement\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amenities with street name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> SELECT COUNT(*)\n",
    "FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) e\n",
    "    JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE key='amenity' UNION ALL SELECT DISTINCT(id) FROM ways_tags WHERE key='amenity') i\n",
    "    ON e.id=i.id\n",
    "WHERE key='street';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "1423\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amenities with house number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> SELECT COUNT(*)\n",
    "FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) e\n",
    "    JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE key='amenity' UNION ALL SELECT DISTINCT(id) FROM ways_tags WHERE key='amenity') i\n",
    "    ON e.id=i.id\n",
    "WHERE key='housenumber';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "883\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amenities with street name and house number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> SELECT COUNT(*)\n",
    "FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) e\n",
    "    JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE key='amenity' UNION ALL SELECT DISTINCT(id) FROM ways_tags WHERE key='amenity') i\n",
    "    ON e.id=i.id\n",
    "    JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE key='street' UNION ALL SELECT DISTINCT(id) FROM ways_tags WHERE key='street') o\n",
    "    ON i.id=o.id\n",
    "WHERE key='housenumber';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "879\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of amenities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> SELECT COUNT(*)\n",
    "FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) e\n",
    "    JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE key='amenity' UNION ALL SELECT DISTINCT(id) FROM ways_tags WHERE key='amenity') i\n",
    "    ON e.id=i.id\n",
    "WHERE key='amenity';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "2325\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results of the queries, only 37.8% (879/2325) of the amenities have information about their location (street name and house number). It would be interesting improve this percentage to users have access to more detailed information when consulting amenities in the OpenStreetMap dataset. Although amenities have the geographic position (latitude and longitude), this kind of information is not suitable for users to get the location of a place. Not only the address is a useful information, but also the phone number, opening hours, wheelchair access, etc. A way to deal with this problem is to getting access to datasets that provide description about the location of amenities and programmatically update the missing addresses. However, there could be some inconveniences when performing this task: \n",
    "+ Finding a reliable dataset to avoid importing wrong data\n",
    "+ The conflict of the amenity name between the two datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I used data cleaning techniques to audit the OpenStreetMap dataset of the region of Santo André. After converting the OSM XML file into CSV format and importing it into a SQL database, I performed some queries to identify some problems in the dataset. With the problems revealed, I corrected them using the audit.py file. <br />\n",
    "This project was very challenging and very difficult to complete. I struggled a lot to understand how the audit.py and data.py files work and how I could adjust these files programmatically to clean the OpenStreetMap dataset. Other difficulties include understanding the structure of the OpenStreetMap dataset, using regular expressions to search for inconsistent words and performing SQL queries to answer some questions. This project is in its initial stage. There are lots of data to be standardized, cleaned, completed and corrected."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
